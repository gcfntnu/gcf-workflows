# To run the pipeline, do:
#
#    snakemake -kp --cores=NCORES --use-conda --conda-prefix=$HOME/.snakemake all
#    snakemake -p --cores=1 postprocess
#
# Note that the pipeline postprocessing ('snakemake postprocess') is separated from
# the rest of the pipeline ('snakemake all').  This is because in a multi-sample run,
# it's likely that at least one pipeline stage will fail.  The postprocessing script
# should handle failed pipeline stages gracefully, by substituting placeholder values
# when expected pipeline output files are absent.  However, this confuses snakemake's
# dependency tracking, so there seems to be no good alternative to separating piepline
# processing and postprocessing into 'all' and 'postprocess' targets.
#
# Related: because pipeline stages can fail, we recommend running 'snakemake all'
# with the -k flag ("Go on with independent jobs if a job fails").


####################################################################################################

from snakemake.utils import validate
import pandas as pd
import os, sys

# The config file contains a high-level summary of pipeline configuration and inputs.
# It is ingested by the Snakefile, and also intended to be human-readable.
# For an example config file, see pipeline/example_config.yaml in the covid-19-sequencing repo.

# read and validate config.yaml
if '--configfile' in sys.argv:
    config_filename = os.path.abspath(sys.argv[sys.argv.index('--configfile')+1])
    # arguments don't line up
    if not os.path.exists(config_filename):
        print("Invalid filepath for configfile. Looking for default config.yaml")
        configfile: "config.yaml"
        config_filename = os.path.join(os.getcwd(), "config.yaml")
    else:
        configfile: config_filename
else:
    configfile: "config.yaml"
    config_filename = os.path.join(os.getcwd(), "config.yaml")

validate(config, 'resources/config.schema.yaml')

# read and validate sample table specified in config.schema.yaml
samples = pd.read_table(config['samples'], sep=',')
validate(samples, 'resources/sample.schema.yaml')

# set output directory
exec_dir = os.getcwd()
workdir: os.path.abspath(config['result_dir'])

# throw error if duplicate sample names in table
if samples['sample'].duplicated().any():
    print("Duplicate sample names in sample table, please fix and restart")
    exit(1)

# get sample names 
sample_names = sorted(samples['sample'].drop_duplicates().values)

def get_input_fastq_files(sample_name, r):
    sample_fastqs = samples[samples['sample'] == sample_name]
    if r == '1':
        relpath = sample_fastqs['r1_path'].values[0]
    elif r == '2':
        relpath = sample_fastqs['r2_path'].values[0]

    return os.path.abspath(os.path.join(exec_dir, relpath))


######################################   High-level targets   ######################################
rule signal_raw_read_data_symlinks:
    input: expand('{sn}/raw_fastq/{sn}_R{r}.fastq.gz', sn=sample_names, r=[1,2])

rule signal_remove_adapters:
    input: expand('{sn}/adapter_trimmed/{sn}_R{r}_val_{r}.fq.gz', sn=sample_names, r=[1,2]),
           expand('{sn}/adapter_trimmed/{sn}_R{r}_val_{r}_posttrim_filter.fq.gz', sn=sample_names, r=[1,2]),

rule signal_host_removed_raw_reads:
    input: expand('{sn}/host_removal/{sn}_R{r}.fastq.gz', sn=sample_names, r=[1,2]),

rule signal_fastqc:
    input: expand('{sn}/raw_fastq/{sn}_R{r}_fastqc.html', sn=sample_names, r=[1,2]),
           expand('{sn}/adapter_trimmed/{sn}_R{r}_val_{r}_fastqc.html', sn=sample_names, r=[1,2]),
           expand('{sn}/mapped_clean_reads/{sn}_R{r}_fastqc.html', sn=sample_names, r=[1,2])

rule signal_clean_reads:
    input:
       expand("{sn}/core/{sn}_viral_reference.mapping.primertrimmed.bam", sn=sample_names),
       expand('{sn}/mapped_clean_reads/{sn}_R{r}.fastq.gz', sn=sample_names, r=[1,2])

rule signal_consensus:
    input: expand('{sn}/core/{sn}.consensus.fa', sn=sample_names)

rule signal_ivar_variants:
    input: expand('{sn}/core/{sn}_ivar_variants.tsv', sn=sample_names)

rule signal_breseq:
    input: expand('{sn}/breseq/{sn}_output/index.html', sn=sample_names)
    
rule signal_coverage:
    input: expand('{sn}/coverage/{sn}_depth.txt', sn=sample_names)

rule signal_coverage_plot:
    input: expand('{sn}/coverage/{sn}_coverage_plot.png', sn=sample_names)

rule signal_kraken2:
    input: expand('{sn}/kraken2/{sn}_kraken2.out', sn=sample_names)

rule signal_quast:
    input: expand('{sn}/quast/{sn}_quast_report.html', sn=sample_names)

rule signal_config_sample_log:
    input: 
        config_filename,
        config['samples']


if config['run_breseq']:
    rule signal_all:
        input:
            rules.signal_raw_read_data_symlinks.input,
            rules.signal_host_removed_raw_reads.input,
            rules.signal_remove_adapters.input,
            rules.signal_fastqc.input,
            rules.signal_clean_reads.input,
            rules.signal_consensus.input,
            rules.signal_ivar_variants.input,
            rules.signal_coverage.input,
            rules.signal_coverage_plot.input,
            rules.signal_kraken2.input,
            rules.signal_quast.input,
            rules.signal_config_sample_log.input,
            rules.signal_breseq.input
else:
    rule signal_all:
        input:
            rules.signal_raw_read_data_symlinks.input,
            rules.signal_host_removed_raw_reads.input,
            rules.signal_remove_adapters.input,
            rules.signal_fastqc.input,
            rules.signal_clean_reads.input,
            rules.signal_consensus.input,
            rules.signal_ivar_variants.input,
            rules.signal_coverage.input,
            rules.signal_coverage_plot.input,
            rules.signal_kraken2.input,
            rules.signal_quast.input,
            rules.signal_config_sample_log.input,


rule signal_postprocess:
    conda: 
        'conda_envs/postprocessing.yaml'
    singularity: 'docker://gcfntnu/signal-postprocessing'
    params:
        sample_csv_filename = os.path.join(exec_dir, config['samples']),
        postprocess_script_path = os.path.join(exec_dir, 'scripts', 'signal_postprocess.py')
    shell:
        '{params.postprocess_script_path} {params.sample_csv_filename}'


rule signal_ncov_tools:
    # can't use the one in the ncov-tool dir as it has to include snakemake
    conda:
        'ncov-tools/workflow/envs/environment.yml'
    params:
        exec_dir = exec_dir,
        result_dir = os.path.basename(config['result_dir']),
        amplicon_bed = os.path.join(exec_dir, config['amplicon_loc_bed']),
        primer_bed = os.path.join(exec_dir, config['scheme_bed']),
        viral_reference_genome = os.path.join(exec_dir, config['viral_reference_genome']),
        phylo_include_seqs = os.path.join(exec_dir, config['phylo_include_seqs'])
    input:
        consensus = expand('{sn}/core/{sn}.consensus.fa', sn=sample_names),
        primertrimmed_bams = expand("{sn}/core/{sn}_viral_reference.mapping.primertrimmed.sorted.bam", sn=sample_names),
        bams = expand("{sn}/core/{sn}_viral_reference.mapping.bam", sn=sample_names),
        variants = expand("{sn}/core/{sn}_ivar_variants.tsv", sn=sample_names)
    script: "scripts/ncov-tools.py"
        
        
################################# Copy config and sample table to output folder ##################
rule signal_copy_config_sample_log:
    output: 
        config = os.path.basename(config_filename),
        sample_table=config["samples"]
    input:
        origin_config = os.path.join(exec_dir, os.path.relpath(config_filename, exec_dir)),
        origin_sample_table = os.path.join(exec_dir, config['samples'])
    shell:
        """
        cp {input.origin_config} {output.config}
        cp {input.origin_sample_table} {output.sample_table}
        """

#################################   Based on scripts/assemble.sh   #################################
rule signal_link_raw_data:
    priority: 4
    output:
        '{sn}/raw_fastq/{sn}_R{r}.fastq.gz'
    input:
        lambda wildcards: get_input_fastq_files(wildcards.sn, wildcards.r)
    shell:
        'ln -s {input} {output}'

rule signal_run_raw_fastqc:
    conda: 'conda_envs/trim_qc.yaml'
    singularity: 'docker://gcfntnu/signal-trim-qc'
    output:
        r1_fastqc = '{sn}/raw_fastq/{sn}_R1_fastqc.html',
        r2_fastqc = '{sn}/raw_fastq/{sn}_R2_fastqc.html'
    input:
        r1 = '{sn}/raw_fastq/{sn}_R1.fastq.gz',
        r2 = '{sn}/raw_fastq/{sn}_R2.fastq.gz'
    benchmark:
        '{sn}/benchmarks/{sn}_raw_fastqc.benchmark.tsv'
    params:
        output_prefix = '{sn}/raw_fastq'
    log:
        '{sn}/raw_fastq/{sn}_fastqc.log'
    shell:
        """
        fastqc -o {params.output_prefix} {input} 2> {log}
        """

########################## Human Host Removal ################################
rule signal_raw_reads_composite_reference_bwa_map:
    threads: 2
    conda: 'conda_envs/snp_mapping.yaml'
    singularity: 'docker://gcfntnu/signal-snp-mapping'
    output:
        '{sn}/host_removal/{sn}_viral_and_nonmapping_reads.bam',
    input:
        raw_r1 = '{sn}/raw_fastq/{sn}_R1.fastq.gz',
        raw_r2 = '{sn}/raw_fastq/{sn}_R2.fastq.gz'
    benchmark:
        "{sn}/benchmarks/{sn}_composite_reference_bwa_map.benchmark.tsv"
    log:
        '{sn}/host_removal/{sn}_human_read_mapping.log'
    params:
       composite_index = os.path.join(exec_dir, config['composite_reference']),
       script_path = os.path.join(exec_dir, "scripts", "filter_non_human_reads.py"),
       viral_contig_name = config['viral_reference_contig_name']
    shell:
        '(bwa mem -t {threads} {params.composite_index} '
        '{input.raw_r1} {input.raw_r2} | '
        '{params.script_path} -c {params.viral_contig_name} > {output}) 2> {log}'

rule signal_get_host_removed_reads:
    threads: 2
    conda: 'conda_envs/snp_mapping.yaml'
    singularity: 'docker://gcfntnu/signal-snp-mapping'
    output:
        r1 = '{sn}/host_removal/{sn}_R1.fastq.gz',
        r2 = '{sn}/host_removal/{sn}_R2.fastq.gz',
        s = '{sn}/host_removal/{sn}_singletons.fastq.gz',
        bam = '{sn}/host_removal/{sn}_viral_and_nonmapping_reads_filtered_sorted.bam'
    input:
        '{sn}/host_removal/{sn}_viral_and_nonmapping_reads.bam',
    benchmark:
        "{sn}/benchmarks/{sn}_get_host_removed_reads.benchmark.tsv"
    log:
        '{sn}/host_removal/{sn}_samtools_fastq.log'
    shell:
        """
        samtools view -b {input} | samtools sort -n -@{threads} > {output.bam} 2> {log}
        samtools fastq -1 {output.r1} -2 {output.r2} -s {output.s} {output.bam} 2>> {log} 
        """

###### Based on github.com/connor-lab/ncov2019-artic-nf/blob/master/modules/illumina.nf#L124 ######

rule signal_run_trimgalore:
    threads: 2
    priority: 2
    conda: 'conda_envs/trim_qc.yaml'
    singularity: 'docker://gcfntnu/signal-trim-qc'
    output:
        '{sn}/adapter_trimmed/{sn}_R1_val_1.fq.gz',
        '{sn}/adapter_trimmed/{sn}_R2_val_2.fq.gz',
        '{sn}/adapter_trimmed/{sn}_R1_val_1_fastqc.html',
        '{sn}/adapter_trimmed/{sn}_R2_val_2_fastqc.html'
    input:
        raw_r1 = '{sn}/host_removal/{sn}_R1.fastq.gz',
        raw_r2 = '{sn}/host_removal/{sn}_R2.fastq.gz'
    log:
        '{sn}/adapter_trimmed/{sn}_trim_galore.log'
    benchmark:
        "{sn}/benchmarks/{sn}_trimgalore.benchmark.tsv"
    params:
        min_len = config['min_len'],
        min_qual = config['min_qual'],
        output_prefix = '{sn}/adapter_trimmed'
    shell:
        'trim_galore --quality {params.min_qual} --length {params.min_len} '
        ' -o {params.output_prefix} --cores {threads} --fastqc '
        '--paired {input.raw_r1} {input.raw_r2} 2> {log}'

rule signal_run_filtering_of_residual_adapters:
    threads: 2
    priority: 2
    conda: 
        'conda_envs/snp_mapping.yaml'
    singularity: 'docker://gcfntnu/signal-snp-mapping'
    input:
        r1 = '{sn}/adapter_trimmed/{sn}_R1_val_1.fq.gz',
        r2 = '{sn}/adapter_trimmed/{sn}_R2_val_2.fq.gz'
    output:
        '{sn}/adapter_trimmed/{sn}_R1_val_1_posttrim_filter.fq.gz',
        '{sn}/adapter_trimmed/{sn}_R2_val_2_posttrim_filter.fq.gz'
    params:
        script_path = os.path.join(exec_dir, "scripts", "filter_residual_adapters.py")
    shell:
        """
        python {params.script_path} --input_R1 {input.r1} --input_R2 {input.r2}
        """
       
rule signal_viral_reference_bwa_build:
    conda: 
        'conda_envs/snp_mapping.yaml'
    singularity: 'docker://gcfntnu/signal-snp-mapping'
    output:
        '{sn}/core/viral_reference.bwt'
    input:
        reference = os.path.join(exec_dir, config['viral_reference_genome']),
    log:
        '{sn}/core/{sn}_viral_reference_bwa-build.log'
    benchmark:
        "{sn}/benchmarks/{sn}_reference_bwa_build.benchmark.tsv"
    params:
        output_prefix = "{sn}/core/viral_reference"
    shell:
        'bwa index -p {params.output_prefix} {input} >{log} 2>&1'


rule signal_viral_reference_bwa_map:
    threads: 2
    conda: 'conda_envs/snp_mapping.yaml'
    singularity: 'docker://gcfntnu/signal-snp-mapping'
    output:
        '{sn}/core/{sn}_viral_reference.bam'
    input:
        r1 = '{sn}/adapter_trimmed/{sn}_R1_val_1_posttrim_filter.fq.gz',
        r2 = '{sn}/adapter_trimmed/{sn}_R2_val_2_posttrim_filter.fq.gz',
        ref = '{sn}/core/viral_reference.bwt'
    benchmark:
        "{sn}/benchmarks/{sn}_viral_reference_bwa_map.benchmark.tsv"
    log:
        '{sn}/core/{sn}_viral_reference_bwa.log'
    params:
       ref_prefix = '{sn}/core/viral_reference'
    shell:
        '(bwa mem -t {threads} {params.ref_prefix} '
        '{input.r1} {input.r2} | '
        'samtools view -bS | samtools sort -@{threads} -o {output}) 2> {log}'



rule signal_run_bed_primer_trim:
    conda: 'conda_envs/ivar.yaml'
    singularity: 'docker://gcfntnu/signal-ivar'
    input:
        "{sn}/core/{sn}_viral_reference.bam"
    output:
        sorted_trimmed_mapped_bam = "{sn}/core/{sn}_viral_reference.mapping.primertrimmed.sorted.bam",
        trimmed_mapped_bam = "{sn}/core/{sn}_viral_reference.mapping.primertrimmed.bam",
        mapped_bam = "{sn}/core/{sn}_viral_reference.mapping.bam"
    benchmark:
        "{sn}/benchmarks/{sn}_bed_primer_trim.benchmark.tsv"
    log:
        "{sn}/core/{sn}_ivar_trim.log"
    params:
        scheme_bed = os.path.join(exec_dir, config['scheme_bed']),
        ivar_output_prefix = "{sn}/core/{sn}_viral_reference.mapping.primertrimmed",
        min_len = config['min_len'],
        min_qual = config['min_qual'],
        primer_pairs = config['primer_pairs_tsv']
    shell:
        'samtools view -F4 -o {output.mapped_bam} {input}; '
        'samtools index {output.mapped_bam}; '
        'ivar trim -e -i {output.mapped_bam} -b {params.scheme_bed} '
        '-m {params.min_len} -q {params.min_qual} '
        '{params.primer_pairs} '
        '-p {params.ivar_output_prefix} 2> {log}; '
        'samtools sort -o {output.sorted_trimmed_mapped_bam} '
        '{output.trimmed_mapped_bam}'


rule signal_run_fastqc_on_mapped_reads:
    conda: 'conda_envs/trim_qc.yaml'
    singularity: 'docker://gcfntnu/signal-trim-qc'
    output:
        r1_fastqc = '{sn}/mapped_clean_reads/{sn}_R1_fastqc.html',
        r2_fastqc = '{sn}/mapped_clean_reads/{sn}_R2_fastqc.html'
    input:
        r1 = '{sn}/mapped_clean_reads/{sn}_R1.fastq.gz',
        r2 = '{sn}/mapped_clean_reads/{sn}_R2.fastq.gz'
    benchmark:
        '{sn}/benchmarks/{sn}_clean_fastqc.benchmark.tsv'
    params:
        output_prefix = '{sn}/mapped_clean_reads'
    log:
        '{sn}/mapped_clean_reads/{sn}_fastqc.log'
    shell:
        """
        fastqc -o {params.output_prefix} {input} 2> {log}
        """

rule signal_get_mapping_reads:
    priority: 2
    conda: 'conda_envs/snp_mapping.yaml'
    singularity: 'docker://gcfntnu/signal-snp-mapping'
    output:
        r1 = '{sn}/mapped_clean_reads/{sn}_R1.fastq.gz',
        r2 = '{sn}/mapped_clean_reads/{sn}_R2.fastq.gz',
        s = '{sn}/mapped_clean_reads/{sn}_singletons.fastq.gz',
        bam = '{sn}/mapped_clean_reads/{sn}_sorted_clean.bam'
    input:
        "{sn}/core/{sn}_viral_reference.mapping.primertrimmed.bam",
    benchmark:
        "{sn}/benchmarks/{sn}_get_mapping_reads.benchmark.tsv"
    log:
        '{sn}/mapped_clean_reads/{sn}_samtools_fastq.log'
    shell:
        """
        samtools sort -n {input} -o {output.bam} 2> {log}
        samtools fastq -1 {output.r1} -2 {output.r2} -s {output.s} {output.bam} 2>> {log} 
        """

rule signal_run_ivar_consensus:
    conda: 'conda_envs/ivar.yaml'
    singularity: 'docker://gcfntnu/signal-ivar'
    output:
        '{sn}/core/{sn}.consensus.fa'
    input:
        "{sn}/core/{sn}_viral_reference.mapping.primertrimmed.sorted.bam"
    log:
        '{sn}/core/{sn}_ivar_consensus.log'
    benchmark:
        "{sn}/benchmarks/{sn}_ivar_consensus.benchmark.tsv"
    params:
        mpileup_depth = config['mpileup_depth'],
        ivar_min_coverage_depth = config['ivar_min_coverage_depth'],
        ivar_freq_threshold = config['ivar_freq_threshold'],
        output_prefix = '{sn}/core/{sn}.consensus',
    shell:
        '(samtools mpileup -aa -A -d {params.mpileup_depth} -Q0 {input} | '
        'ivar consensus -t {params.ivar_freq_threshold} '
        '-m {params.ivar_min_coverage_depth} -n N -p {params.output_prefix}) '
        '2>{log}'

rule signal_index_viral_reference:
    # from @jts both mpileup and ivar need a reference .fai file and will create 
    # it when it doesn't exist. 
    # When they're run in a pipe like mpileup | ivar there's a race condition 
    # that causes the error
    conda: 'conda_envs/ivar.yaml'
    singularity: 'docker://gcfntnu/signal-ivar'
    output:
        os.path.join(exec_dir, config['viral_reference_genome']) + ".fai"
    input:
        os.path.join(exec_dir, config['viral_reference_genome']),
    shell:
        'samtools faidx {input}'

    
rule signal_run_ivar_variants:
    conda: 'conda_envs/ivar.yaml'
    singularity: 'docker://gcfntnu/signal-ivar'
    output:
        '{sn}/core/{sn}_ivar_variants.tsv'
    input:
        reference = os.path.join(exec_dir, config['viral_reference_genome']),
        indexed_reference = os.path.join(exec_dir, config['viral_reference_genome']) + ".fai",
        read_bam = "{sn}/core/{sn}_viral_reference.mapping.primertrimmed.sorted.bam",
        viral_reference_gff = os.path.join(exec_dir, config['viral_reference_feature_coords'])
    log:
        '{sn}/core/{sn}_ivar_variants.log'
    benchmark:
        "{sn}/benchmarks/{sn}_ivar_variants.benchmark.tsv"
    params:
        output_prefix = '{sn}/core/{sn}_ivar_variants',
        ivar_min_coverage_depth = config['ivar_min_coverage_depth'],
        ivar_min_freq_threshold = config['ivar_min_freq_threshold'],
        ivar_min_variant_quality = config['ivar_min_variant_quality'],
    shell:
        '(samtools mpileup -aa -A -d 0 --reference {input.reference} -B '
            '-Q 0 {input.read_bam} | '
        'ivar variants -r {input.reference} -m {params.ivar_min_coverage_depth} '
        '-p {params.output_prefix} -q {params.ivar_min_variant_quality} '
        '-t {params.ivar_min_freq_threshold} -g {input.viral_reference_gff}) 2> {log}'


################################   Based on scripts/breseq.sh   ####################################

rule signal_run_breseq:
    threads: 4
    priority: 1
    conda: 'conda_envs/snp_mapping.yaml'
    singularity: 'docker://gcfntnu/signal-snp-mapping'
    output:
        '{sn}/breseq/{sn}_output/index.html'
    input:
        expand('{{sn}}/mapped_clean_reads/{{sn}}_R{r}.fastq.gz', r=[1,2])
    log:
        '{sn}/breseq/{sn}_breseq.log',
    benchmark:
        "{sn}/benchmarks/{sn}_run_breseq.benchmark.tsv"
    params:
        ref = os.path.join(exec_dir, config['breseq_reference']),
        outdir = '{sn}/breseq',
        unlabelled_output_dir = '{sn}/breseq/output',
        labelled_output_dir = '{sn}/breseq/{sn}_output'
    shell:
        """
        breseq --reference {params.ref} --num-processors {threads} --polymorphism-prediction --brief-html-output --output {params.outdir} {input} > {log} 2>&1
        mv -T {params.unlabelled_output_dir} {params.labelled_output_dir}
        """


##################  Based on scripts/hisat2.sh and scripts/coverage_stats_avg.sh  ##################


rule signal_coverage_depth:
    conda: 'conda_envs/snp_mapping.yaml'
    singularity: 'docker://gcfntnu/signal-snp-mapping'
    output:
        '{sn}/coverage/{sn}_depth.txt'
    input:
        "{sn}/core/{sn}_viral_reference.mapping.primertrimmed.sorted.bam"
    benchmark:
        "{sn}/benchmarks/{sn}_coverage_depth.benchmark.tsv"
    shell:
        'bedtools genomecov -d -ibam {input} >{output}'

rule signal_generate_coverage_plot:
    conda: 'conda_envs/postprocessing.yaml'
    singularity: 'docker://gcfntnu/signal-postprocessing'
    output: 
        '{sn}/coverage/{sn}_coverage_plot.png' 
    input:
        '{sn}/coverage/{sn}_depth.txt'
    params:
        script_path = os.path.join(exec_dir, "scripts", "generate_coverage_plot.py")
    shell:
        "python {params.script_path} {input} {output}"
    
################################   Based on scripts/kraken2.sh   ###################################


rule signal_run_kraken2:
    threads: 1
    conda: 'conda_envs/trim_qc.yaml'
    singularity: 'docker://gcfntnu/signal-trim-qc'
    output:
        '{sn}/kraken2/{sn}_kraken2.out'
    input:
        r1 = '{sn}/adapter_trimmed/{sn}_R1_val_1_posttrim_filter.fq.gz',
        r2 = '{sn}/adapter_trimmed/{sn}_R2_val_2_posttrim_filter.fq.gz'
    log:
        '{sn}/kraken2/{sn}_kraken2.log'
    benchmark:
        "{sn}/benchmarks/{sn}_run_kraken2.benchmark.tsv"
    params:
        outdir = '{sn}/kraken2',
        db = os.path.join(exec_dir, config['kraken2_db']),
        labelled_output = '{sn}_kraken2.out',
        labelled_report = '{sn}_kraken2.report',
        labelled_unclassified_reads = '{sn}_kraken2_unclassified_reads#',
        labelled_classified_reads = '{sn}_kraken2_classified_reads#'
    shell:
        'cd {params.outdir} '
        '&& kraken2'
            ' --db {params.db}'
            ' --threads {threads}'
            ' --quick --unclassified-out "{params.labelled_unclassified_reads}"'
            ' --classified-out "{params.labelled_classified_reads}"'
            ' --output {params.labelled_output}'
            ' --paired --gzip-compressed'
            ' ../../{input.r1} ../../{input.r2}'
            ' --report {params.labelled_report}'
            ' 2>../../{log}'


##################################  Based on scripts/quast.sh   ####################################


rule signal_run_quast:
    threads: 1
    conda: 'conda_envs/assembly_qc.yaml'
    singularity: 'docker://gcfntnu/signal-assembly-qc'
    output:
         '{sn}/quast/{sn}_quast_report.html'
    input:
         '{sn}/core/{sn}.consensus.fa'
    log:
         '{sn}/quast/{sn}_quast.log'
    benchmark:
        "{sn}/benchmarks/{sn}_run_quast.benchmark.tsv"
    params:
         outdir = '{sn}/quast',
         genome = os.path.join(exec_dir, config['viral_reference_genome']),
         fcoords = os.path.join(exec_dir, config['viral_reference_feature_coords']),
         sample_name = '{sn}_quast_report',
         unlabelled_reports = '{sn}/quast/report.*'
    shell:
         'quast {input} -r {params.genome} -g {params.fcoords} --output-dir {params.outdir} --threads {threads} >{log} && '
         'for f in {params.unlabelled_reports}; do mv $f ${{f/report/{params.sample_name}}}; done'

