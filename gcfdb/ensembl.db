#-*- mode:snakemake -*-
"""ENSEMBL reference genomes

"""
import urllib.request as request
from contextlib import closing


def _get_current_ensembl():
    """Get current release number for Ensembl by parsing top-level current_README.
    """
    url = 'ftp.ensembl.org/pub/current_README'
    protocol = 'http://'
    proxies = config.get('proxy', {}).get('server')
    if proxies:
        proxy_support = request.ProxyHandler(proxies)
        request.install_opener(request.build_opener(proxy_support))
    with closing(request.urlopen(protocol + url)) as response:
        try:
            out = response.read()
            release = int(re.findall(b".*Release\s(\d+)\s+", out)[0])
        except: 
            raise ValueError("release parse error or protocol error")
    return str(release)

if DB_CONF.get('release') is None or DB_CONF.get('release') == '':
    DB_CONF['release'] = _get_current_ensembl()
    config['db']['ensembl'] = DB_CONF


def _parse_species_txt(tab, sep='\t'):
    SP = {}
    header = tab.pop(0).split(sep)
    for line in tab:
        els = line.split(sep)
        row = dict(zip(header, els))
        species = row.pop('species')
        if species in SP:
            raise ValueError('found duplicate species!')
        if species == 'homo_sapiens':
            #fixme?
            row['assembly'] = row['assembly'].split('.')[0]
        SP[species] = row
    return SP


def _init_ensembl_from_organism():
    """Parse species annotations by given organsim and release number
    """
    url = 'ftp.ensembl.org/pub/release-{}/species_EnsemblVertebrates.txt'.format(str(config['db']['ensembl']['release']))
    protocol = 'http://'
    proxies = config.get('proxy', {}).get('server')
    if proxies:
        proxy_support = request.ProxyHandler(proxies)
        request.install_opener(request.build_opener(proxy_support))
    with closing(request.urlopen(protocol + url)) as response:
        out = response.read()
    try:
        tab = out.decode('utf-8').splitlines()
    except:
        raise ValueError('failed to parse url')
    SP = _parse_species_txt(tab)
    return SP.get(config['organism'])

if DB_CONF.get('assembly') is None or DB_CONF.get('assembly') == '':
    sp = _init_ensembl_from_organism()
    DB_CONF['assembly'] = sp['assembly']
    DB_CONF['taxid'] = sp.get('taxonomy_id')
    DB_CONF['acc_id'] = sp.get('assembly_accession')
    DB_CONF['organism_name'] = sp['#name']
    config['db']['ensembl'] = DB_CONF


rule init_ensembl_species:
    params:
        url = 'http://ftp.ensembl.org/pub/release-{wildcards.release}/species_EnsemblVertebrates.txt',
        proxy = config.get('proxy', {}).get('wget', '')
    threads:
        48
    output:
        join(EXT_DIR, 'ensembl', 'release-{release}', 'lookup_tables', 'species_EnsemblVertebrates.txt')
    shell:
        'wget {params.proxy} -O- ftp://ftp.ensembl.org/pub/release-{wildcards.release}/species_EnsemblVertebrates.txt > {output}'

checkpoint build_ftp_table:
    input:
        rules.init_ensembl_species.output
    output:
        txt = join(EXT_DIR, 'ensembl', 'release-{release}', 'lookup_tables', '{organism}_ftp.txt')
    params:
        script = srcdir('scripts/build_ensembl_lookup.py'),
        proxy = config.get('proxy', {}).get('server', {}).get('ftp', 'none')
    singularity:
        'docker://' + config['docker']['default']
    shell:
        'python {params.script} {input} --proxy {params.proxy} --release {wildcards.release} --organism {wildcards.organism} --output {output}'


def get_ensembl_ftp(wildcards, input, sub='genome'):
    fn = checkpoints.build_ftp_table.get(**wildcards).output[0]
    with open(input[0]) as fh:
        txt = fh.read().splitlines()
        header = txt.pop(0).split('\t')
        for line in txt:
            els = line.split('\t')
            row = dict(zip(header, els))
            if row['species'] == wildcards.organism:
                return row['ftp_{}'.format(sub)]
    
rule ensembl_genome:
    input:
        lambda wildcards: checkpoints.build_ftp_table.get(**wildcards).output[0]
    params:
        date = datetime.now().strftime("%d-%m-%Y"),
        release = DB_CONF['release'],
        proxy = config['proxy'].get('wget', ''),
        url = lambda wildcards, input: get_ensembl_ftp(wildcards, input, 'genome')
    output:
        join(EXT_DIR, 'ensembl', 'release-{release}', '{organism}', '{assembly}', 'fasta', 'genome.fa')
    threads: 
        24
    log:
        join(EXT_DIR, 'ensembl', 'release-{release}', '{organism}', '{assembly}', 'logs', 'genome.log')
    shell: 
        """
        wget {params.proxy} -O- {params.url} | gunzip -c > {output}
        echo 'Ensembl DNA,release-{params.release},{params.url},{params.date}' > {log}
        """

rule ensembl_noncoding:
    input:
        lambda wildcards: checkpoints.build_ftp_table.get(**wildcards).output[0]
    params:
        date = datetime.now().strftime("%d-%m-%Y"),
        release = DB_CONF['release'],
        proxy = config['proxy'].get('wget', ''),
        url = lambda wildcards, input: get_ensembl_ftp(wildcards, input, 'ncrna')
    output:
        join(EXT_DIR, 'ensembl', 'release-{release}', '{organism}', '{assembly}', 'fasta', 'ncrna.fa')
    threads: 
        24
    log:
        join(EXT_DIR, 'ensembl', 'release-{release}', '{organism}', '{assembly}', 'logs', 'ncrna.log')
    shell: 
        """
        wget {params.proxy} -O- {params.url} | gunzip -c > {output}
        echo 'Ensembl DNA,release-{params.release},{params.url},{params.date}' > {log}
        """


rule ensembl_gff:
    input:
        lambda wildcards: checkpoints.build_ftp_table.get(**wildcards).output[0]
    params:
        date = datetime.now().strftime("%d-%m-%Y"),
        release = DB_CONF['release'],
        proxy = config['proxy'].get('wget', ''),
        url = lambda wildcards, input: get_ensembl_ftp(wildcards, input, 'gff')
    output:
        join(EXT_DIR, 'ensembl', 'release-{release}', '{organism}', '{assembly}', 'anno', 'genes.gff')
    threads: 
        24
    log:
        join(EXT_DIR, 'ensembl', 'release-{release}', '{organism}', '{assembly}', 'logs', 'gff.log')
    shell: 
        """
        wget {params.proxy} -O- {params.url} | gunzip -c > {output}
        echo 'Ensembl GFF,release-{params.release},{params.url},{params.date}' > {log}
        """

rule ensembl_gtf:
    input:
        lambda wildcards: checkpoints.build_ftp_table.get(**wildcards).output[0]
    params:
        date = datetime.now().strftime("%d-%m-%Y"),
        release = DB_CONF['release'],
        proxy = config['proxy'].get('wget', ''),
        url = lambda wildcards, input: get_ensembl_ftp(wildcards, input, 'gtf')
    output:
        join(EXT_DIR, 'ensembl', 'release-{release}', '{organism}', '{assembly}', 'anno', 'genes.gtf')
    threads: 
        24
    log:
        join(EXT_DIR, 'ensembl', 'release-{release}', '{organism}', '{assembly}', 'logs', 'gtf.log')
    shell: 
        """
        wget {params.proxy} -O- {params.url} | gunzip -c > {output}
        echo 'Ensembl GTF,release-{params.release},{params.url},{params.date}' > {log}
        """ 

rule ensembl_transcriptome:
    input:
        join(EXT_DIR, 'ensembl', 'release-{release}', '{organism}', '{assembly}', 'fasta', 'gtf.gffread.transcripts.fa')
    output:
        join(EXT_DIR, 'ensembl', 'release-{release}', '{organism}', '{assembly}', 'fasta', 'transcriptome.fa')
    shell:
        'ln -s {input} {output}'
