#-*- mode:snakemake -*-

extra_conf_fn = srcdir('star.config')
if os.path.exists(extra_conf_fn):
    with open(extra_conf_fn) as fh:
        c  = yaml.load(fh, Loader=Loader) or {}
        update_config2(config, c)

#config
ORG = config.get('organism', 'homo_sapiens')
STAR_INTERIM = join(QUANT_INTERIM, 'star')
STAR_CONF = config['quant'].get('star', {})


def starsolo_R1(wildcards):
    return ','.join(get_filtered_fastq_R1(wildcards))

def starsolo_R2(wildcards):
    return ','.join(get_filtered_fastq_R2(wildcards))


rule starsolo_genome_index:
    input: 
        genome = join(REF_DIR, 'fasta', 'genome.fa'),
        gtf = join(REF_DIR, 'genes', 'genes.gtf')
    output:
        join(REF_DIR, 'starsolo', 'SA')
    params:
        index_dir =  join(REF_DIR, 'starsolo'),
        readlength = config.get('read_geometry', [28, 98])[-1]
    threads:
        48
    log:
        join(REF_DIR, 'logs', 'STAR.index.log')
    singularity:
        'docker://' + config['docker']['star']
    shell:
        'STAR '
        '--runThreadN {threads} '
        '--runMode genomeGenerate '
        '--genomeDir {params.index_dir} '
        '--genomeFastaFiles {input.genome} '
        '--sjdbGTFfile {input.gtf} '
        '--sjdbOverhang {params.readlength} '
        '&& mv Log.out {log} '

READ_LENGTH = config.get('read_geometry', [28, 98])[-1]
if config['db']['reference_db'] == '10xgenomics':
    # rebuild genome to match current star version
    REF_GENOME = join(REF_DIR, 'index', 'genome', 'starsolo', 'r_{}'.format(READ_LENGTH), 'SA')
else:
    REF_GENOME = join(REF_DIR, 'index', 'genome', 'star', 'r_{}'.format(READ_LENGTH), 'SA')

rule starsolo_quant:
    input:
        R1 = get_filtered_fastq_R1,
        R2 = get_filtered_fastq_R2,
        genome = REF_GENOME,
        whitelist = join(EXT_DIR, '10xgenomics', config.get('organism'), "release-{}".format(config['db']['10xgenomics']['release']), config['db']['10xgenomics']['assembly'], LIBPREP['starsolo']['whitelist'])
    params:
        outdir = join(STAR_INTERIM, '{sample}') + '/',
        genome_dir = os.path.dirname(REF_GENOME),
        cb_len = LIBPREP['starsolo']['cb_len'],
        umi_len = LIBPREP['starsolo']['umi_len'],
        umi_start = LIBPREP['starsolo']['umi_start'],
        R1 = starsolo_R1,
        R2 = starsolo_R2,
        extra_args = '--genomeLoad LoadAndKeep --soloFeatures Gene GeneFull SJ Velocyto Transcript3p ' 
    threads:
        48
    output:
        barcodes = join(STAR_INTERIM, '{sample}', 'Solo.out', 'Gene', 'filtered', 'barcodes.tsv'),
        gene_stats = join(STAR_INTERIM, '{sample}', 'Solo.out', 'Gene', 'Features.stats'),
        gene_summary = join(STAR_INTERIM, '{sample}', 'Solo.out', 'Gene', 'Summary.csv'),
        genes = join(STAR_INTERIM, '{sample}', 'Solo.out', 'Gene', 'filtered', 'features.tsv'),
        mtx = join(STAR_INTERIM, '{sample}', 'Solo.out','Gene', 'filtered', 'matrix.mtx'),
        raw_mtx = join(STAR_INTERIM, '{sample}', 'Solo.out','Gene', 'raw', 'matrix.mtx'),
        barcodes_full = join(STAR_INTERIM, '{sample}', 'Solo.out', 'GeneFull', 'filtered', 'barcodes.tsv'),
        bam = join(STAR_INTERIM, '{sample}', 'Aligned.sortedByCoord.out.bam')
    singularity:
        'docker://' + config['docker']['star']
    benchmark:
        'benchmark/starsolo/{sample}-starsolo.txt'
    log:
        star = join(STAR_INTERIM, '{sample}', 'Log.final.out'),
        barcodes = join(STAR_INTERIM, '{sample}', 'Solo.out', 'Gene', 'Barcodes.stats'),
        umi_cell = join(STAR_INTERIM, '{sample}', 'Solo.out', 'Gene', 'UMIperCellSorted.txt')
        
    shell:
        'STAR --soloType CB_UMI_Simple '
        ' --readFilesCommand zcat '
        '--soloCBwhitelist {input.whitelist} '
        '--readFilesIn {params.R2} {params.R1} '
        '--genomeDir {params.genome_dir} '
        '--outFileNamePrefix {params.outdir} '
        '--soloCBlen {params.cb_len} '
        '--soloUMIlen {params.umi_len} '
        '--soloUMIstart {params.umi_start} '
        '--outSAMtype BAM SortedByCoordinate '
        '--outSAMattributes CR CY UR UY CB UB NH '
        '--limitBAMsortRAM 24000000000 ' 
        '--runThreadN {threads} '
        '{params.extra_args} '

rule starsolo_bam:
    input:
        rules.starsolo_quant.output.bam
    output:
        join(STAR_INTERIM, '{sample}', '{sample}_Aligned.sortedByCoord.out.bam')
    shell:
        'ln -sr {input} {output}'

        

rule starsolo_clean_shmem:
    input:
        expand(rules.starsolo_quant.output, sample=SAMPLES)
    params:
        genome_dir = rules.starsolo_quant.params.genome_dir
    output:
        temp(touch(join(STAR_INTERIM, '.starsolo.mem.cleaned')))
    singularity:
        'docker://' + config['docker']['star']
    shell:
        'STAR --genomeDir {params.genome_dir} --genomeLoad Remove || echo "no shared mem"'

rule scanpy_starsolo:
    input:
        mat = join(STAR_INTERIM, '{sample}', 'Solo.out', 'Gene', 'raw', 'matrix.mtx'),
        mem_clean = rules.starsolo_clean_shmem.output
    params:
        script = srcdir('scripts/convert_scanpy.py')
    output:
        join(STAR_INTERIM, '{sample}', 'scanpy', '{sample}.h5ad')
    singularity:
        'docker://' + config['docker']['scanpy']
    threads:
        48
    shell:
        'python {params.script} {input.mat} -f star -o {output} -v --identify-doublets --identify-empty-droplets '
 
rule scanpy_aggr_starsolo:
    input:
        input = expand(rules.starsolo_quant.output.raw_mtx, sample=SAMPLES),
        mem_clean = rules.starsolo_clean_shmem.output
    params:
        script = srcdir('scripts/convert_scanpy.py'),
        norm = config['quant']['aggregate']['norm']
    output:
        join(QUANT_INTERIM, 'aggregate', 'star', 'scanpy', 'all_samples_aggr.h5ad')
    singularity:
        'docker://' + config['docker']['scanpy']
    threads:
        48
    shell:
        'python {params.script} '
        '{input.input} '
        '-o {output} '
        '-f star '
        '--normalize {params.norm} '
        '--identify-doublets '
        '--identify-empty-droplets '
        '-v '       

rule starsolo_bam_merge:
    input:
        expand(rules.starsolo_quant.output, sample=SAMPLES)
    output:
        join(QUANT_INTERIM, 'aggregate', 'star', 'sorted.bam')
    threads:
        48
    singularity:
        'docker://' + config['docker']['sambamba']
    shell:
        'sambamba merge -t 8 {output} {input}'
